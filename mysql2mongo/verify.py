#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®è¿ç§»å®Œæ•´æ€§éªŒè¯å·¥å…·
ç”¨äºéªŒè¯MySQLåˆ°MongoDBæ•°æ®è¿ç§»çš„å®Œæ•´æ€§
æ”¯æŒè¿ç§»å…ƒæ•°æ®å­—æ®µéªŒè¯ã€æ•°æ®å†…å®¹éªŒè¯å’Œå­—æ®µæ˜ å°„éªŒè¯
æ”¯æŒè‡ªåŠ¨ä¿®å¤è¿ç§»å¤±è´¥æˆ–é—æ¼çš„æ•°æ®
"""

import json
import sys
import random
from datetime import datetime, timedelta
from migration_tool import MySQLConnector, MongoDBConnector, MigrationLogger


def verify_migration_metadata(collection, table_name, expected_source='mysql'):
    """
    éªŒè¯è¿ç§»å…ƒæ•°æ®å­—æ®µå®Œæ•´æ€§
    
    Args:
        collection: MongoDBé›†åˆå¯¹è±¡
        table_name: è¡¨å
        expected_source: æœŸæœ›çš„sourceå­—æ®µå€¼
        
    Returns:
        (æ˜¯å¦é€šè¿‡, é”™è¯¯ä¿¡æ¯)
    """
    total_count = collection.count_documents({})
    
    if total_count == 0:
        return True, "ç©ºè¡¨ï¼Œè·³è¿‡å…ƒæ•°æ®éªŒè¯"
    
    # éªŒè¯sourceå­—æ®µ
    source_count = collection.count_documents({'source': expected_source})
    if source_count != total_count:
        return False, f"sourceå­—æ®µéªŒè¯å¤±è´¥: {source_count}/{total_count}æ¡è®°å½•sourceå­—æ®µæ­£ç¡®"
    
    # éªŒè¯migrationTimeå­—æ®µ
    time_count = collection.count_documents({
        'migrationTime': {'$type': 'date'}
    })
    if time_count != total_count:
        return False, f"migrationTimeå­—æ®µéªŒè¯å¤±è´¥: {time_count}/{total_count}æ¡è®°å½•æ—¶é—´æ ¼å¼æ­£ç¡®"
    
    # éªŒè¯è¿ç§»æ—¶é—´åˆç†æ€§ï¼ˆæœ€è¿‘7å¤©å†…ï¼‰
    recent_time = datetime.now() - timedelta(days=7)
    recent_count = collection.count_documents({
        'migrationTime': {'$gte': recent_time}
    })
    if recent_count != total_count:
        return True, f"éƒ¨åˆ†æ•°æ®è¿ç§»æ—¶é—´è¾ƒæ—§: {recent_count}/{total_count}æ¡è®°å½•åœ¨æœ€è¿‘7å¤©å†…"
    
    return True, f"è¿ç§»å…ƒæ•°æ®éªŒè¯é€šè¿‡: {total_count}æ¡è®°å½•"


def verify_data_content_complete(mysql_connector, mongo_connector, table_name, batch_size=1000):
    """
    å®Œæ•´éªŒè¯æ•°æ®å†…å®¹ä¸€è‡´æ€§ï¼ˆæ’é™¤è¿ç§»å…ƒæ•°æ®ï¼‰
    
    Args:
        mysql_connector: MySQLè¿æ¥å™¨
        mongo_connector: MongoDBè¿æ¥å™¨
        table_name: è¡¨å
        batch_size: æ‰¹æ¬¡å¤„ç†å¤§å°
        
    Returns:
        (æ˜¯å¦é€šè¿‡, é”™è¯¯ä¿¡æ¯, éªŒè¯è¯¦æƒ…)
    """
    # è·å–MySQLæ€»è®°å½•æ•°
    total_count = mysql_connector.get_table_count(table_name)
    
    if total_count == 0:
        return True, "ç©ºè¡¨ï¼Œè·³è¿‡å†…å®¹éªŒè¯", {}
    
    print(f"å¼€å§‹å®Œæ•´éªŒè¯è¡¨ {table_name} çš„æ•°æ®å†…å®¹ï¼Œå…± {total_count:,} æ¡è®°å½•...")
    
    collection = mongo_connector.database[table_name]
    
    # æ’é™¤è¿ç§»å…ƒæ•°æ®å­—æ®µè¿›è¡Œæ¯”è¾ƒ
    metadata_fields = ['migrationTime', 'source', '_id']
    
    comparison_results = []
    all_passed = True
    processed_count = 0
    
    # åˆ†æ‰¹å¤„ç†æ‰€æœ‰è®°å½•
    for offset in range(0, total_count, batch_size):
        current_batch_size = min(batch_size, total_count - offset)
        
        # ä»MySQLè·å–å½“å‰æ‰¹æ¬¡æ•°æ®
        mysql_data = mysql_connector.fetch_data(table_name, current_batch_size, offset)
        
        # è·å–å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰ID
        mysql_ids = [str(doc.get('id')) for doc in mysql_data]
        
        # ä»MongoDBæ‰¹é‡è·å–å¯¹åº”æ•°æ®
        mongo_docs = {}
        cursor = collection.find({'_id': {'$in': mysql_ids}})
        for doc in cursor:
            mongo_docs[doc['_id']] = doc
        
        # é€æ¡æ¯”è¾ƒæ•°æ®å†…å®¹
        for i, mysql_doc in enumerate(mysql_data):
            mysql_id = str(mysql_doc.get('id'))
            mongo_doc = mongo_docs.get(mysql_id)
            
            if not mongo_doc:
                comparison_results.append({
                    'index': processed_count + i,
                    'mysql_id': mysql_id,
                    'status': 'âŒ å¤±è´¥',
                    'error': 'MongoDBä¸­æ‰¾ä¸åˆ°å¯¹åº”è®°å½•'
                })
                all_passed = False
                continue
            
            # è¿‡æ»¤æ‰è¿ç§»å…ƒæ•°æ®å­—æ®µ
            mysql_filtered = {k: v for k, v in mysql_doc.items() 
                             if k not in metadata_fields and k != 'id'}
            mongo_filtered = {k: v for k, v in mongo_doc.items() 
                             if k not in metadata_fields}
            
            # æ¯”è¾ƒæ•°æ®å†…å®¹
            if mysql_filtered == mongo_filtered:
                comparison_results.append({
                    'index': processed_count + i,
                    'mysql_id': mysql_id,
                    'status': 'âœ… é€šè¿‡',
                    'details': f"{len(mysql_filtered)}ä¸ªå­—æ®µä¸€è‡´"
                })
            else:
                # æ‰¾å‡ºä¸ä¸€è‡´çš„å­—æ®µ
                differences = []
                all_keys = set(mysql_filtered.keys()) | set(mongo_filtered.keys())
                
                for key in all_keys:
                    mysql_val = mysql_filtered.get(key)
                    mongo_val = mongo_filtered.get(key)
                    
                    if mysql_val != mongo_val:
                        differences.append(f"{key}: MySQL={mysql_val}, MongoDB={mongo_val}")
                
                comparison_results.append({
                    'index': processed_count + i,
                    'mysql_id': mysql_id,
                    'status': 'âŒ å¤±è´¥',
                    'error': f"{len(differences)}ä¸ªå­—æ®µä¸ä¸€è‡´",
                    'differences': differences[:3]  # åªæ˜¾ç¤ºå‰3ä¸ªå·®å¼‚
                })
                all_passed = False
        
        processed_count += len(mysql_data)
        print(f"  å·²å¤„ç† {processed_count:,}/{total_count:,} æ¡è®°å½•...")
    
    if all_passed:
        return True, f"æ•°æ®å†…å®¹å®Œæ•´éªŒè¯é€šè¿‡: {total_count}æ¡è®°å½•å…¨éƒ¨ä¸€è‡´", comparison_results
    else:
        failed_count = sum(1 for r in comparison_results if r['status'] == 'âŒ å¤±è´¥')
        return False, f"æ•°æ®å†…å®¹éªŒè¯å¤±è´¥: {failed_count}/{total_count}æ¡è®°å½•ä¸ä¸€è‡´", comparison_results


def verify_field_mapping(table_name, table_mappings_file="table_mappings.json"):
    """
    éªŒè¯å­—æ®µæ˜ å°„æ­£ç¡®æ€§
    
    Args:
        table_name: è¡¨å
        table_mappings_file: å­—æ®µæ˜ å°„é…ç½®æ–‡ä»¶
        
    Returns:
        (æ˜¯å¦é€šè¿‡, é”™è¯¯ä¿¡æ¯, æ˜ å°„è¯¦æƒ…)
    """
    try:
        with open(table_mappings_file, 'r', encoding='utf-8') as f:
            table_mappings = json.load(f)
    except Exception as e:
        return False, f"åŠ è½½å­—æ®µæ˜ å°„æ–‡ä»¶å¤±è´¥: {e}", {}
    
    if table_name not in table_mappings:
        return True, "æœªæ‰¾åˆ°å­—æ®µæ˜ å°„é…ç½®ï¼Œè·³è¿‡éªŒè¯", {}
    
    mappings = table_mappings[table_name].get('transformations', {})
    
    if not mappings:
        return True, "æ— å­—æ®µæ˜ å°„é…ç½®ï¼Œè·³è¿‡éªŒè¯", {}
    
    mapping_results = []
    all_passed = True
    
    for field, mapping in mappings.items():
        target_field = mapping.get('target', field)
        field_type = mapping.get('type', 'æœªçŸ¥')
        
        mapping_results.append({
            'source_field': field,
            'target_field': target_field,
            'field_type': field_type,
            'status': 'âœ… é…ç½®æ­£ç¡®'
        })
    
    return True, f"å­—æ®µæ˜ å°„éªŒè¯é€šè¿‡: {len(mapping_results)}ä¸ªå­—æ®µ", mapping_results


def verify_migration(config_file: str = "config.json", auto_repair: bool = False):
    """
    éªŒè¯æ•°æ®è¿ç§»å®Œæ•´æ€§
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        auto_repair: æ˜¯å¦è‡ªåŠ¨ä¿®å¤å‘ç°çš„é—®é¢˜
    """
    
    # åŠ è½½é…ç½®
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # åˆå§‹åŒ–æ—¥å¿—å’Œè¿æ¥å™¨
    logger = MigrationLogger("verify.log")
    mysql_connector = MySQLConnector(config['mysql'], logger)
    mongo_connector = MongoDBConnector(config['mongodb'], logger)
    
    # è¿æ¥æ•°æ®åº“
    if not mysql_connector.connect():
        print("è¿æ¥MySQLæ•°æ®åº“å¤±è´¥")
        return False
    
    if not mongo_connector.connect():
        print("è¿æ¥MongoDBæ•°æ®åº“å¤±è´¥")
        mysql_connector.disconnect()
        return False
    
    try:
        # è·å–è¦éªŒè¯çš„è¡¨åˆ—è¡¨
        tables = config['verify'].get('tables', [])
        
        # è·å–ä¿®å¤é…ç½®
        repair_config = config.get('repair', {
            'repair_missing': True,
            'repair_inconsistent': True,
            'repair_metadata': True
        })
        
        print("=" * 80)
        print("æ•°æ®è¿ç§»å®Œæ•´æ€§éªŒè¯æŠ¥å‘Š")
        if auto_repair:
            print("ï¼ˆè‡ªåŠ¨ä¿®å¤æ¨¡å¼ï¼‰")
        print("=" * 80)
        
        all_passed = True
        verification_details = {}
        repair_summary = {}
        
        for table_name in tables:
            print(f"\nè¡¨å: {table_name}")
            print("-" * 50)
            
            # è·å–MySQLè®°å½•æ•°
            mysql_count = mysql_connector.get_table_count(table_name)
            
            # è·å–MongoDBè®°å½•æ•°
            mongo_count = mongo_connector.get_collection_count(table_name)
            
            # åŸºç¡€éªŒè¯ï¼šè®°å½•æ•°é‡ä¸€è‡´æ€§
            base_consistent = mysql_count == mongo_count
            base_status = "âœ… é€šè¿‡" if base_consistent else "âŒ å¤±è´¥"
            
            print(f"åŸºç¡€éªŒè¯:")
            print(f"  MySQLè®°å½•æ•°: {mysql_count:,}")
            print(f"  MongoDBè®°å½•æ•°: {mongo_count:,}")
            print(f"  ä¸€è‡´æ€§éªŒè¯: {base_status}")
            
            if not base_consistent:
                print(f"  âŒ å·®å¼‚æ•°é‡: {abs(mysql_count - mongo_count):,}")
                
                # è‡ªåŠ¨ä¿®å¤ï¼šé—æ¼æ•°æ®
                if auto_repair:
                    print("\nğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤é—æ¼æ•°æ®...")
                    repair_success, repair_details = auto_repair_data(
                        mysql_connector, mongo_connector, table_name, repair_config
                    )
                    repair_summary[table_name] = repair_details
                    
                    # é‡æ–°éªŒè¯åŸºç¡€ä¸€è‡´æ€§
                    mongo_count_after_repair = mongo_connector.get_collection_count(table_name)
                    base_consistent_after_repair = mysql_count == mongo_count_after_repair
                    
                    if base_consistent_after_repair:
                        print(f"âœ… ä¿®å¤ååŸºç¡€éªŒè¯é€šè¿‡")
                        base_consistent = True
                    else:
                        print(f"âŒ ä¿®å¤ååŸºç¡€éªŒè¯ä»ç„¶å¤±è´¥")
                        all_passed = False
                else:
                    all_passed = False
            
            # å¦‚æœåŸºç¡€éªŒè¯å¤±è´¥ä¸”æœªä¿®å¤ï¼Œè·³è¿‡å…¶ä»–éªŒè¯
            if not base_consistent:
                verification_details[table_name] = {
                    'base_verification': False,
                    'metadata_verification': 'è·³è¿‡',
                    'content_verification': 'è·³è¿‡',
                    'mapping_verification': 'è·³è¿‡'
                }
                continue
            
            # è¿ç§»å…ƒæ•°æ®éªŒè¯
            collection = mongo_connector.database[table_name]
            metadata_passed, metadata_message = verify_migration_metadata(collection, table_name)
            metadata_status = "âœ… é€šè¿‡" if metadata_passed else "âŒ å¤±è´¥"
            
            print(f"è¿ç§»å…ƒæ•°æ®éªŒè¯: {metadata_status}")
            print(f"  {metadata_message}")
            
            # è‡ªåŠ¨ä¿®å¤ï¼šè¿ç§»å…ƒæ•°æ®
            if not metadata_passed and auto_repair:
                print("\nğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤è¿ç§»å…ƒæ•°æ®...")
                repaired, failed = repair_migration_metadata(mongo_connector, table_name)
                if failed == 0:
                    metadata_passed = True
                    print("âœ… è¿ç§»å…ƒæ•°æ®ä¿®å¤å®Œæˆ")
                else:
                    print("âŒ è¿ç§»å…ƒæ•°æ®ä¿®å¤å¤±è´¥")
            
            # æ•°æ®å†…å®¹å®Œæ•´éªŒè¯ï¼ˆä»…å¯¹éç©ºè¡¨è¿›è¡Œï¼‰
            content_passed, content_message, content_details = True, "ç©ºè¡¨ï¼Œè·³è¿‡", {}
            if mysql_count > 0:
                content_passed, content_message, content_details = verify_data_content_complete(
                    mysql_connector, mongo_connector, table_name, batch_size=1000
                )
            
            content_status = "âœ… é€šè¿‡" if content_passed else "âŒ å¤±è´¥"
            print(f"æ•°æ®å†…å®¹éªŒè¯: {content_status}")
            print(f"  {content_message}")
            
            # è‡ªåŠ¨ä¿®å¤ï¼šä¸ä¸€è‡´æ•°æ®
            if not content_passed and auto_repair:
                print("\nğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤ä¸ä¸€è‡´æ•°æ®...")
                repaired, failed = repair_inconsistent_data(mysql_connector, mongo_connector, table_name)
                if failed == 0:
                    content_passed = True
                    print("âœ… ä¸ä¸€è‡´æ•°æ®ä¿®å¤å®Œæˆ")
                else:
                    print("âŒ ä¸ä¸€è‡´æ•°æ®ä¿®å¤å¤±è´¥")
            
            # å­—æ®µæ˜ å°„éªŒè¯
            mapping_passed, mapping_message, mapping_details = verify_field_mapping(table_name)
            mapping_status = "âœ… é€šè¿‡" if mapping_passed else "âŒ å¤±è´¥"
            
            print(f"å­—æ®µæ˜ å°„éªŒè¯: {mapping_status}")
            print(f"  {mapping_message}")
            
            # æ±‡æ€»éªŒè¯ç»“æœ
            table_passed = base_consistent and metadata_passed and content_passed and mapping_passed
            if not table_passed:
                all_passed = False
            
            verification_details[table_name] = {
                'base_verification': base_consistent,
                'metadata_verification': metadata_passed,
                'content_verification': content_passed,
                'mapping_verification': mapping_passed,
                'content_details': content_details,
                'mapping_details': mapping_details
            }
            
            print(f"\nè¡¨ {table_name} éªŒè¯ç»“æœ: {'âœ… å…¨éƒ¨é€šè¿‡' if table_passed else 'âŒ å­˜åœ¨å¤±è´¥'}")
            print("-" * 50)
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        print("\n" + "=" * 80)
        print("éªŒè¯æ±‡æ€»æŠ¥å‘Š")
        if auto_repair:
            print("ï¼ˆåŒ…å«è‡ªåŠ¨ä¿®å¤ç»“æœï¼‰")
        print("=" * 80)
        
        passed_tables = sum(1 for details in verification_details.values() 
                           if details['base_verification'] and 
                              details['metadata_verification'] and 
                              details['content_verification'] and 
                              details['mapping_verification'])
        
        print(f"æ€»è¡¨æ•°: {len(tables)}")
        print(f"é€šè¿‡è¡¨æ•°: {passed_tables}")
        print(f"å¤±è´¥è¡¨æ•°: {len(tables) - passed_tables}")
        print(f"æ•´ä½“é€šè¿‡ç‡: {passed_tables/len(tables)*100:.1f}%")
        
        # æ˜¾ç¤ºä¿®å¤ç»“æœ
        if auto_repair and repair_summary:
            print("\n" + "-" * 50)
            print("è‡ªåŠ¨ä¿®å¤ç»“æœ")
            print("-" * 50)
            
            total_repaired = 0
            total_failed = 0
            
            for table_name, details in repair_summary.items():
                table_repaired = (details.get('missing_repaired', 0) + 
                                details.get('inconsistent_repaired', 0) + 
                                details.get('metadata_repaired', 0))
                table_failed = (details.get('missing_failed', 0) + 
                              details.get('inconsistent_failed', 0) + 
                              details.get('metadata_failed', 0))
                
                total_repaired += table_repaired
                total_failed += table_failed
                
                if table_repaired > 0 or table_failed > 0:
                    print(f"è¡¨ {table_name}:")
                    if details.get('missing_repaired', 0) > 0:
                        print(f"  é—æ¼æ•°æ®ä¿®å¤: âœ… {details['missing_repaired']}æ¡")
                    if details.get('missing_failed', 0) > 0:
                        print(f"  é—æ¼æ•°æ®ä¿®å¤: âŒ {details['missing_failed']}æ¡å¤±è´¥")
                    if details.get('inconsistent_repaired', 0) > 0:
                        print(f"  ä¸ä¸€è‡´æ•°æ®ä¿®å¤: âœ… {details['inconsistent_repaired']}æ¡")
                    if details.get('inconsistent_failed', 0) > 0:
                        print(f"  ä¸ä¸€è‡´æ•°æ®ä¿®å¤: âŒ {details['inconsistent_failed']}æ¡å¤±è´¥")
                    if details.get('metadata_repaired', 0) > 0:
                        print(f"  è¿ç§»å…ƒæ•°æ®ä¿®å¤: âœ… {details['metadata_repaired']}æ¡")
                    if details.get('metadata_failed', 0) > 0:
                        print(f"  è¿ç§»å…ƒæ•°æ®ä¿®å¤: âŒ {details['metadata_failed']}æ¡å¤±è´¥")
            
            print(f"\næ€»è®¡ä¿®å¤: âœ… {total_repaired}æ¡æˆåŠŸ, âŒ {total_failed}æ¡å¤±è´¥")
        
        if all_passed:
            print("\nğŸ‰ æ‰€æœ‰è¡¨çš„æ•°æ®è¿ç§»å®Œæ•´æ€§éªŒè¯é€šè¿‡ï¼")
            if auto_repair:
                print("ğŸ”§ è‡ªåŠ¨ä¿®å¤åŠŸèƒ½å·²æˆåŠŸå¤„ç†æ‰€æœ‰é—®é¢˜")
        else:
            print("\nâš ï¸  éƒ¨åˆ†è¡¨çš„æ•°æ®è¿ç§»å®Œæ•´æ€§éªŒè¯å¤±è´¥")
            if auto_repair:
                print("ğŸ”§ è‡ªåŠ¨ä¿®å¤åŠŸèƒ½å·²å°è¯•ä¿®å¤ï¼Œä½†ä»æœ‰éƒ¨åˆ†é—®é¢˜æ— æ³•è§£å†³")
            
            print("\nè¯¦ç»†å¤±è´¥ä¿¡æ¯:")
            for table_name, details in verification_details.items():
                if not (details['base_verification'] and 
                       details['metadata_verification'] and 
                       details['content_verification'] and 
                       details['mapping_verification']):
                    print(f"\nè¡¨ {table_name}:")
                    if not details['base_verification']:
                        print("  âŒ åŸºç¡€éªŒè¯å¤±è´¥")
                    if not details['metadata_verification']:
                        print("  âŒ è¿ç§»å…ƒæ•°æ®éªŒè¯å¤±è´¥")
                    if not details['content_verification']:
                        print("  âŒ æ•°æ®å†…å®¹éªŒè¯å¤±è´¥")
                    if not details['mapping_verification']:
                        print("  âŒ å­—æ®µæ˜ å°„éªŒè¯å¤±è´¥")
        
        return all_passed
        
    finally:
        # æ–­å¼€æ•°æ®åº“è¿æ¥
        mysql_connector.disconnect()
        mongo_connector.disconnect()


def check_progress():
    """æ£€æŸ¥è¿ç§»è¿›åº¦æ–‡ä»¶"""
    progress_file = "migration_progress.json"
    
    try:
        with open(progress_file, 'r', encoding='utf-8') as f:
            progress = json.load(f)
        
        print("=" * 80)
        print("è¿ç§»è¿›åº¦æ£€æŸ¥")
        print("=" * 80)
        
        if progress:
            for table_name, info in progress.items():
                print(f"è¡¨å: {table_name}")
                print(f"  å½“å‰åç§»é‡: {info.get('offset', 0):,}")
                print(f"  å·²è¿ç§»æ•°é‡: {info.get('migrated_count', 0):,}")
                print(f"  æœ€åæ›´æ–°æ—¶é—´: {info.get('last_update', 'æœªçŸ¥')}")
                print("-" * 50)
            print("âš ï¸  å­˜åœ¨æœªå®Œæˆçš„è¿ç§»è¿›åº¦ï¼Œå¯ä»¥ä½¿ç”¨æ–­ç‚¹ç»­ä¼ åŠŸèƒ½ç»§ç»­è¿ç§»")
        else:
            print("âœ… æ²¡æœ‰æœªå®Œæˆçš„è¿ç§»è¿›åº¦")
        
    except FileNotFoundError:
        print("âœ… è¿ç§»è¿›åº¦æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¡¨ç¤ºæ²¡æœ‰æœªå®Œæˆçš„è¿ç§»ä»»åŠ¡")
    except Exception as e:
        print(f"âŒ è¯»å–è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")


def repair_missing_data(mysql_connector, mongo_connector, table_name, batch_size=1000):
    """
    ä¿®å¤é—æ¼çš„æ•°æ®
    
    Args:
        mysql_connector: MySQLè¿æ¥å™¨
        mongo_connector: MongoDBè¿æ¥å™¨
        table_name: è¡¨å
        batch_size: æ‰¹æ¬¡å¤§å°
        
    Returns:
        (ä¿®å¤æˆåŠŸæ•°é‡, ä¿®å¤å¤±è´¥æ•°é‡)
    """
    import time
    
    print(f"å¼€å§‹ä¿®å¤è¡¨ {table_name} çš„é—æ¼æ•°æ®...")
    start_time = time.time()
    
    # è·å–MySQLæ€»è®°å½•æ•°
    mysql_count = mysql_connector.get_table_count(table_name)
    
    # è·å–MongoDBæ€»è®°å½•æ•°
    mongo_count = mongo_connector.get_collection_count(table_name)
    
    if mysql_count == mongo_count:
        print(f"âœ… è¡¨ {table_name} è®°å½•æ•°é‡ä¸€è‡´ï¼Œæ— éœ€ä¿®å¤")
        return 0, 0
    
    print(f"æ£€æµ‹åˆ°æ•°æ®å·®å¼‚: MySQL={mysql_count:,}, MongoDB={mongo_count:,}")
    print(f"é¢„è®¡éœ€è¦å¤„ç† {mysql_count:,} æ¡è®°å½•...")
    
    # è·å–MongoDBä¸­å·²æœ‰çš„IDé›†åˆ
    collection = mongo_connector.database[table_name]
    existing_ids = set()
    
    try:
        print("æ­£åœ¨è·å–MongoDBç°æœ‰IDé›†åˆ...")
        cursor = collection.find({}, {'_id': 1})
        total_mongo_ids = 0
        for doc in cursor:
            existing_ids.add(doc['_id'])
            total_mongo_ids += 1
            if total_mongo_ids % 10000 == 0:
                print(f"  å·²åŠ è½½ {total_mongo_ids:,} ä¸ªID...")
        print(f"âœ… å·²è·å–MongoDBç°æœ‰IDé›†åˆ: {total_mongo_ids:,} ä¸ªID")
    except Exception as e:
        print(f"âŒ è·å–MongoDBç°æœ‰IDå¤±è´¥: {e}")
        return 0, 1
    
    # åˆ†æ‰¹è·å–MySQLæ•°æ®å¹¶æ£€æŸ¥é—æ¼
    offset = 0
    repaired_count = 0
    failed_count = 0
    total_processed = 0
    last_progress_time = time.time()
    
    print(f"å¼€å§‹æ‰«æMySQLæ•°æ®ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size:,}")
    
    while offset < mysql_count:
        current_time = time.time()
        
        # æ¯30ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
        if current_time - last_progress_time > 30:
            progress = (offset / mysql_count) * 100
            elapsed_time = current_time - start_time
            estimated_total_time = (elapsed_time / offset) * mysql_count if offset > 0 else 0
            remaining_time = estimated_total_time - elapsed_time if estimated_total_time > elapsed_time else 0
            
            print(f"  è¿›åº¦: {offset:,}/{mysql_count:,} ({progress:.1f}%) - "
                  f"å·²ä¿®å¤: {repaired_count:,} - "
                  f"è€—æ—¶: {elapsed_time:.0f}s - "
                  f"é¢„è®¡å‰©ä½™: {remaining_time:.0f}s")
            last_progress_time = current_time
        
        # è·å–å½“å‰æ‰¹æ¬¡æ•°æ®
        batch_start_time = time.time()
        mysql_data = mysql_connector.fetch_data(table_name, batch_size, offset)
        fetch_time = time.time() - batch_start_time
        
        if not mysql_data:
            print(f"  å·²å¤„ç†å®Œæ‰€æœ‰æ•°æ®ï¼Œæ€»å¤„ç†: {total_processed:,} æ¡")
            break
        
        # ç­›é€‰å‡ºé—æ¼çš„æ•°æ®
        missing_data = []
        check_start_time = time.time()
        
        for doc in mysql_data:
            mysql_id = str(doc.get('id'))
            if mysql_id not in existing_ids:
                # åˆ›å»ºæ–°æ–‡æ¡£ï¼ˆæ’é™¤MySQLçš„idå­—æ®µï¼Œåªä¿ç•™æ­£ç¡®çš„å­—æ®µæ˜ å°„ï¼‰
                new_doc = {}
                
                # å¤åˆ¶MySQLæ–‡æ¡£çš„æ‰€æœ‰å­—æ®µï¼Œä½†æ’é™¤idå­—æ®µ
                for key, value in doc.items():
                    if key != 'id':  # æ’é™¤MySQLçš„idå­—æ®µ
                        new_doc[key] = value
                
                # è®¾ç½®MongoDBçš„ä¸»é”®å’Œè¿ç§»å…ƒæ•°æ®
                new_doc['_id'] = mysql_id
                new_doc['source'] = 'mysql'
                new_doc['migrationTime'] = datetime.now()
                missing_data.append(new_doc)
        
        check_time = time.time() - check_start_time
        total_processed += len(mysql_data)
        
        # æ’å…¥é—æ¼çš„æ•°æ®
        if missing_data:
            insert_start_time = time.time()
            try:
                result = collection.insert_many(missing_data, ordered=False)
                repaired_count += len(result.inserted_ids)
                insert_time = time.time() - insert_start_time
                
                print(f"  æ‰¹æ¬¡ {offset//batch_size + 1}: "
                      f"è·å–æ•°æ® {fetch_time:.2f}s, "
                      f"æ£€æŸ¥é—æ¼ {check_time:.2f}s, "
                      f"æ’å…¥ {insert_time:.2f}s - "
                      f"ä¿®å¤ {len(result.inserted_ids)} æ¡é—æ¼æ•°æ®")
                
            except BulkWriteError as e:
                # éƒ¨åˆ†æ’å…¥æˆåŠŸçš„æƒ…å†µ
                inserted_count = len(e.details.get('writeErrors', []))
                repaired_count += inserted_count
                failed_count += len(missing_data) - inserted_count
                print(f"  éƒ¨åˆ†ä¿®å¤å¤±è´¥: æˆåŠŸ{inserted_count}æ¡, å¤±è´¥{len(missing_data) - inserted_count}æ¡")
            except Exception as e:
                failed_count += len(missing_data)
                print(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {e}")
        else:
            # æ²¡æœ‰é—æ¼æ•°æ®ï¼Œæ˜¾ç¤ºè¿›åº¦
            if total_processed % (batch_size * 10) == 0:  # æ¯10ä¸ªæ‰¹æ¬¡æ˜¾ç¤ºä¸€æ¬¡
                print(f"  æ‰¹æ¬¡ {offset//batch_size + 1}: "
                      f"è·å–æ•°æ® {fetch_time:.2f}s, "
                      f"æ£€æŸ¥é—æ¼ {check_time:.2f}s - "
                      f"æ— é—æ¼æ•°æ®")
        
        offset += batch_size
    
    total_time = time.time() - start_time
    print(f"âœ… è¡¨ {table_name} ä¿®å¤å®Œæˆ: "
          f"æˆåŠŸ{repaired_count:,}æ¡, "
          f"å¤±è´¥{failed_count:,}æ¡, "
          f"æ€»è€—æ—¶{total_time:.1f}ç§’")
    
    return repaired_count, failed_count


def repair_inconsistent_data(mysql_connector, mongo_connector, table_name, batch_size=1000):
    """
    ä¿®å¤ä¸ä¸€è‡´çš„æ•°æ®ï¼ˆå…¨é‡æ£€æŸ¥ï¼‰
    
    Args:
        mysql_connector: MySQLè¿æ¥å™¨
        mongo_connector: MongoDBè¿æ¥å™¨
        table_name: è¡¨å
        batch_size: æ‰¹æ¬¡å¤§å°
        
    Returns:
        (ä¿®å¤æˆåŠŸæ•°é‡, ä¿®å¤å¤±è´¥æ•°é‡)
    """
    import time
    
    print(f"å¼€å§‹å…¨é‡æ£€æŸ¥å¹¶ä¿®å¤è¡¨ {table_name} çš„ä¸ä¸€è‡´æ•°æ®...")
    start_time = time.time()
    
    # è·å–MySQLæ€»è®°å½•æ•°
    total_count = mysql_connector.get_table_count(table_name)
    
    if total_count == 0:
        print(f"âœ… è¡¨ {table_name} ä¸ºç©ºï¼Œæ— éœ€ä¿®å¤")
        return 0, 0
    
    print(f"å…¨é‡æ£€æŸ¥ {total_count:,} æ¡è®°å½•ï¼Œæ‰¹æ¬¡å¤§å°: {batch_size:,}")
    
    # ä»MongoDBè·å–å¯¹åº”æ•°æ®å¹¶æ£€æŸ¥ä¸ä¸€è‡´
    collection = mongo_connector.database[table_name]
    
    # æ’é™¤è¿ç§»å…ƒæ•°æ®å­—æ®µè¿›è¡Œæ¯”è¾ƒ
    metadata_fields = ['migrationTime', 'source', '_id']
    
    repaired_count = 0
    failed_count = 0
    checked_count = 0
    offset = 0
    last_progress_time = time.time()
    
    while offset < total_count:
        current_time = time.time()
        
        # æ¯10ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ï¼ˆæ›´é¢‘ç¹çš„åé¦ˆï¼‰
        if current_time - last_progress_time > 10:
            progress = (offset / total_count) * 100
            elapsed_time = current_time - start_time
            estimated_total_time = (elapsed_time / offset) * total_count if offset > 0 else 0
            remaining_time = estimated_total_time - elapsed_time if estimated_total_time > elapsed_time else 0
            
            # ä½¿ç”¨è¿›åº¦æ¡æ ·å¼æ˜¾ç¤º
            bar_length = 40
            filled_length = int(bar_length * offset // total_count)
            bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
            
            print(f"\r  [{bar}] {offset:,}/{total_count:,} ({progress:.1f}%) - "
                  f"å·²ä¿®å¤: {repaired_count:,} - "
                  f"è€—æ—¶: {elapsed_time:.0f}s - "
                  f"é¢„è®¡å‰©ä½™: {remaining_time:.0f}s", end='', flush=True)
            last_progress_time = current_time
        
        # è·å–å½“å‰æ‰¹æ¬¡æ•°æ®
        batch_start_time = time.time()
        mysql_data = mysql_connector.fetch_data(table_name, batch_size, offset)
        fetch_time = time.time() - batch_start_time
        
        if not mysql_data:
            print(f"\n  å·²å¤„ç†å®Œæ‰€æœ‰æ•°æ®ï¼Œæ€»æ£€æŸ¥: {checked_count:,} æ¡")
            break
        
        check_start_time = time.time()
        batch_inconsistent_count = 0
        batch_consistent_count = 0
        batch_inconsistent_ids = []  # å­˜å‚¨ä¸ä¸€è‡´è®°å½•çš„ID
        
        for mysql_doc in mysql_data:
            checked_count += 1
            
            # è·å–å¯¹åº”çš„MongoDBæ–‡æ¡£
            mysql_id = str(mysql_doc.get('id'))
            mongo_doc = collection.find_one({'_id': mysql_id})
            
            if not mongo_doc:
                # è®°å½•ä¸å­˜åœ¨ï¼Œç”±é—æ¼ä¿®å¤åŠŸèƒ½å¤„ç†
                continue
            
            # è¿‡æ»¤æ‰è¿ç§»å…ƒæ•°æ®å­—æ®µ
            # æ³¨æ„ï¼šMySQLçš„idå­—æ®µå¯¹åº”MongoDBçš„_idå­—æ®µï¼Œéƒ½éœ€è¦è¿‡æ»¤
            mysql_filtered = {k: v for k, v in mysql_doc.items() 
                             if k not in metadata_fields and k != 'id'}
            mongo_filtered = {k: v for k, v in mongo_doc.items() 
                             if k not in metadata_fields and k != '_id'}
            
            # æ£€æŸ¥è¿‡æ»¤åå­—æ®µå·®å¼‚
            mysql_keys = set(mysql_filtered.keys())
            mongo_keys = set(mongo_filtered.keys())
            
            # æ¯”è¾ƒæ•°æ®å†…å®¹
            if mysql_filtered != mongo_filtered:
                batch_inconsistent_count += 1
                batch_inconsistent_ids.append(mysql_id)
                
                # å¦‚æœå­—æ®µä¸ä¸€è‡´ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                if mysql_keys != mongo_keys:
                    missing_in_mongo = mysql_keys - mongo_keys
                    missing_in_mysql = mongo_keys - mysql_keys
                    print(f"\n  âš ï¸  è®°å½• {mysql_id} å­—æ®µåä¸ä¸€è‡´:")
                    print(f"     MongoDBç¼ºå¤±å­—æ®µ: {list(missing_in_mongo)}")
                    print(f"     MySQLç¼ºå¤±å­—æ®µ: {list(missing_in_mysql)}")
                
                # è¯¦ç»†åˆ†ææ•°æ®å·®å¼‚
                differences = []
                # åªæ¯”è¾ƒä¸¤ä¸ªå­—å…¸ä¸­éƒ½å­˜åœ¨çš„å­—æ®µï¼ˆäº¤é›†ï¼‰
                common_keys = mysql_keys.intersection(mongo_keys)
                
                for key in common_keys:
                    mysql_val = mysql_filtered[key]  # ç›´æ¥è®¿é—®ï¼Œå› ä¸ºkeyè‚¯å®šå­˜åœ¨
                    mongo_val = mongo_filtered[key]  # ç›´æ¥è®¿é—®ï¼Œå› ä¸ºkeyè‚¯å®šå­˜åœ¨
                    
                    if mysql_val != mongo_val:
                        # å°è¯•ç±»å‹è½¬æ¢åå†æ¯”è¾ƒ
                        try:
                            # å¤„ç†æ—¥æœŸæ—¶é—´ç±»å‹
                            if isinstance(mysql_val, datetime) and isinstance(mongo_val, datetime):
                                if mysql_val == mongo_val:
                                    continue
                            
                            # å¤„ç†æ•°å­—ç±»å‹
                            if isinstance(mysql_val, (int, float)) and isinstance(mongo_val, (int, float)):
                                if float(mysql_val) == float(mongo_val):
                                    continue
                            
                            # å¤„ç†å­—ç¬¦ä¸²ç±»å‹
                            if isinstance(mysql_val, str) and isinstance(mongo_val, str):
                                if mysql_val.strip() == mongo_val.strip():
                                    continue
                        except:
                            pass
                        
                        differences.append(f"{key}: MySQL={mysql_val} ({type(mysql_val).__name__}), "
                                          f"MongoDB={mongo_val} ({type(mongo_val).__name__})")
                
                # æ˜¾ç¤ºå®Œæ•´çš„æ•°æ®å¯¹æ¯”
                print(f"\n  ğŸ” è®°å½• {mysql_id} æ•°æ®ä¸ä¸€è‡´:")
                
                # æ˜¾ç¤ºMySQLå®Œæ•´æ•°æ®ï¼ˆæ’é™¤è¿ç§»å…ƒæ•°æ®ï¼‰
                print(f"     MySQLæ•°æ®:")
                for key, value in mysql_filtered.items():
                    value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                    print(f"       {key}: {value_str} ({type(value).__name__})")
                
                # æ˜¾ç¤ºMongoDBå®Œæ•´æ•°æ®ï¼ˆæ’é™¤è¿ç§»å…ƒæ•°æ®ï¼‰
                print(f"     MongoDBæ•°æ®:")
                for key, value in mongo_filtered.items():
                    value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                    print(f"       {key}: {value_str} ({type(value).__name__})")
                
                # æ˜¾ç¤ºå…·ä½“å·®å¼‚
                if differences:
                    print(f"     ğŸ” å…·ä½“å·®å¼‚ ({len(differences)}ä¸ª):")
                    for diff in differences[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ªå·®å¼‚
                        print(f"       {diff}")
                    if len(differences) > 5:
                        print(f"       ... è¿˜æœ‰{len(differences)-5}ä¸ªå·®å¼‚")
                else:
                    print(f"     â„¹ï¸  å­—æ®µä¸€è‡´ä½†æ•°æ®ä¸ä¸€è‡´ï¼ˆå¯èƒ½æ˜¯å­—æ®µç¼ºå¤±å¯¼è‡´ï¼‰")
                
                # æ•°æ®ä¸ä¸€è‡´ï¼Œéœ€è¦ä¿®å¤
                try:
                    # åˆ›å»ºæ›´æ–°æ–‡æ¡£ï¼ˆæ’é™¤MySQLçš„idå­—æ®µï¼Œåªä¿ç•™æ­£ç¡®çš„å­—æ®µæ˜ å°„ï¼‰
                    update_doc = {}
                    
                    # å¤åˆ¶MySQLæ–‡æ¡£çš„æ‰€æœ‰å­—æ®µï¼Œä½†æ’é™¤idå­—æ®µ
                    for key, value in mysql_doc.items():
                        if key != 'id':  # æ’é™¤MySQLçš„idå­—æ®µ
                            update_doc[key] = value
                    
                    # è®¾ç½®MongoDBçš„ä¸»é”®å’Œè¿ç§»å…ƒæ•°æ®
                    update_doc['_id'] = mysql_id
                    update_doc['source'] = 'mysql'
                    update_doc['migrationTime'] = datetime.now()
                    
                    # ä½¿ç”¨replace_oneæ›¿æ¢æ•´ä¸ªæ–‡æ¡£
                    result = collection.replace_one({'_id': mysql_id}, update_doc)
                    
                    if result.modified_count > 0:
                        repaired_count += 1
                        if repaired_count % 50 == 0:  # æ¯ä¿®å¤50æ¡æ˜¾ç¤ºä¸€æ¬¡
                            print(f"\n  ğŸ”§ å·²ä¿®å¤è®°å½• {mysql_id} (ç´¯è®¡: {repaired_count:,})")
                    else:
                        failed_count += 1
                        print(f"\n  âŒ ä¿®å¤è®°å½• {mysql_id} å¤±è´¥")
                        
                except Exception as e:
                    failed_count += 1
                    print(f"\n  âŒ ä¿®å¤è®°å½• {mysql_id} æ—¶å‡ºé”™: {e}")
            else:
                batch_consistent_count += 1
        
        check_time = time.time() - check_start_time
        
        # æ¯æ‰¹æ¬¡éƒ½æ˜¾ç¤ºå¤„ç†ä¿¡æ¯ï¼ˆæ›´é¢‘ç¹çš„åé¦ˆï¼‰
        batch_num = offset//batch_size + 1
        print(f"\n  æ‰¹æ¬¡ {batch_num}: "
              f"è·å–æ•°æ® {fetch_time:.2f}s, "
              f"æ£€æŸ¥æ•°æ® {check_time:.2f}s - "
              f"ä¸€è‡´: {batch_consistent_count}, ä¸ä¸€è‡´: {batch_inconsistent_count}")
        
        # æ˜¾ç¤ºä¸ä¸€è‡´è®°å½•çš„è¯¦ç»†ä¿¡æ¯ï¼ˆæœ€å¤šæ˜¾ç¤º5ä¸ªï¼‰
        if batch_inconsistent_count > 0:
            print(f"     ä¸ä¸€è‡´è®°å½•ID: {', '.join(batch_inconsistent_ids[:5])}")
            if batch_inconsistent_count > 5:
                print(f"     ... è¿˜æœ‰{batch_inconsistent_count - 5}ä¸ªä¸ä¸€è‡´è®°å½•")
        
        # æ¯å¤„ç†10000æ¡è®°å½•æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†ç»Ÿè®¡
        if checked_count % 10000 == 0:
            print(f"  ğŸ“Š ç´¯è®¡ç»Ÿè®¡: æ£€æŸ¥{checked_count:,}æ¡, ä¿®å¤{repaired_count:,}æ¡, å¤±è´¥{failed_count:,}æ¡")
        
        offset += batch_size
    
    total_time = time.time() - start_time
    print(f"âœ… è¡¨ {table_name} å…¨é‡æ•°æ®ä¿®å¤å®Œæˆ: "
          f"æ£€æŸ¥{checked_count:,}æ¡, "
          f"æˆåŠŸ{repaired_count:,}æ¡, "
          f"å¤±è´¥{failed_count:,}æ¡, "
          f"æ€»è€—æ—¶{total_time:.1f}ç§’")
    
    if failed_count == 0:
        print(f"ğŸ‰ è¡¨ {table_name} æ‰€æœ‰æ•°æ®ä¸€è‡´æ€§éªŒè¯é€šè¿‡ï¼")
    else:
        print(f"âš ï¸  è¡¨ {table_name} å­˜åœ¨ {failed_count:,} æ¡æ•°æ®ä¿®å¤å¤±è´¥")
    
    return repaired_count, failed_count


def repair_migration_metadata(mongo_connector, table_name):
    """
    ä¿®å¤è¿ç§»å…ƒæ•°æ®
    
    Args:
        mongo_connector: MongoDBè¿æ¥å™¨
        table_name: è¡¨å
        
    Returns:
        (ä¿®å¤æˆåŠŸæ•°é‡, ä¿®å¤å¤±è´¥æ•°é‡)
    """
    print(f"å¼€å§‹ä¿®å¤è¡¨ {table_name} çš„è¿ç§»å…ƒæ•°æ®...")
    
    collection = mongo_connector.database[table_name]
    
    # æ£€æŸ¥å¹¶ä¿®å¤ç¼ºå¤±çš„è¿ç§»å…ƒæ•°æ®
    repaired_count = 0
    failed_count = 0
    
    try:
        # ä¿®å¤ç¼ºå¤±sourceå­—æ®µçš„è®°å½•
        result_source = collection.update_many(
            {'source': {'$exists': False}}, 
            {'$set': {'source': 'mysql'}}
        )
        
        # ä¿®å¤ç¼ºå¤±migrationTimeå­—æ®µçš„è®°å½•
        result_time = collection.update_many(
            {'migrationTime': {'$exists': False}}, 
            {'$set': {'migrationTime': datetime.now()}}
        )
        
        repaired_count = result_source.modified_count + result_time.modified_count
        
        if result_source.modified_count > 0:
            print(f"  ä¿®å¤äº† {result_source.modified_count} æ¡è®°å½•çš„sourceå­—æ®µ")
        
        if result_time.modified_count > 0:
            print(f"  ä¿®å¤äº† {result_time.modified_count} æ¡è®°å½•çš„migrationTimeå­—æ®µ")
        
        if repaired_count == 0:
            print(f"âœ… è¡¨ {table_name} çš„è¿ç§»å…ƒæ•°æ®å®Œæ•´ï¼Œæ— éœ€ä¿®å¤")
            
    except Exception as e:
        failed_count = 1
        print(f"âŒ ä¿®å¤è¿ç§»å…ƒæ•°æ®å¤±è´¥: {e}")
    
    return repaired_count, failed_count


def auto_repair_data(mysql_connector, mongo_connector, table_name, repair_config):
    """
    è‡ªåŠ¨ä¿®å¤æ•°æ®
    
    Args:
        mysql_connector: MySQLè¿æ¥å™¨
        mongo_connector: MongoDBè¿æ¥å™¨
        table_name: è¡¨å
        repair_config: ä¿®å¤é…ç½®
        
    Returns:
        (æ˜¯å¦ä¿®å¤æˆåŠŸ, ä¿®å¤è¯¦æƒ…)
    """
    print(f"\nå¼€å§‹è‡ªåŠ¨ä¿®å¤è¡¨ {table_name}...")
    print("-" * 50)
    
    repair_details = {
        'missing_repaired': 0,
        'missing_failed': 0,
        'inconsistent_repaired': 0,
        'inconsistent_failed': 0,
        'metadata_repaired': 0,
        'metadata_failed': 0
    }
    
    all_success = True
    
    # ä¿®å¤é—æ¼æ•°æ®
    if repair_config.get('repair_missing', True):
        repaired, failed = repair_missing_data(mysql_connector, mongo_connector, table_name)
        repair_details['missing_repaired'] = repaired
        repair_details['missing_failed'] = failed
        if failed > 0:
            all_success = False
    
    # ä¿®å¤ä¸ä¸€è‡´æ•°æ®
    if repair_config.get('repair_inconsistent', True):
        repaired, failed = repair_inconsistent_data(mysql_connector, mongo_connector, table_name, batch_size=1000)
        repair_details['inconsistent_repaired'] = repaired
        repair_details['inconsistent_failed'] = failed
        if failed > 0:
            all_success = False
    
    # ä¿®å¤è¿ç§»å…ƒæ•°æ®
    if repair_config.get('repair_metadata', True):
        repaired, failed = repair_migration_metadata(mongo_connector, table_name)
        repair_details['metadata_repaired'] = repaired
        repair_details['metadata_failed'] = failed
        if failed > 0:
            all_success = False
    
    print(f"è¡¨ {table_name} è‡ªåŠ¨ä¿®å¤å®Œæˆ")
    print("-" * 50)
    
    return all_success, repair_details


def repair_only_mode(config_file: str = "config.json"):
    """
    ä»…æ‰§è¡Œä¿®å¤æ¨¡å¼
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        (æ˜¯å¦ä¿®å¤æˆåŠŸ)
    """
    # åŠ è½½é…ç½®
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # åˆå§‹åŒ–æ—¥å¿—å’Œè¿æ¥å™¨
    logger = MigrationLogger("verify.log")
    mysql_connector = MySQLConnector(config['mysql'], logger)
    mongo_connector = MongoDBConnector(config['mongodb'], logger)
    
    # è¿æ¥æ•°æ®åº“
    if not mysql_connector.connect():
        print("è¿æ¥MySQLæ•°æ®åº“å¤±è´¥")
        return False
    
    if not mongo_connector.connect():
        print("è¿æ¥MongoDBæ•°æ®åº“å¤±è´¥")
        mysql_connector.disconnect()
        return False
    
    try:
        # è·å–è¦ä¿®å¤çš„è¡¨åˆ—è¡¨
        tables = config['verify'].get('tables', [])
        
        # è·å–ä¿®å¤é…ç½®
        repair_config = config.get('repair', {
            'repair_missing': True,
            'repair_inconsistent': True,
            'repair_metadata': True
        })
        
        print("=" * 80)
        print("æ•°æ®ä¿®å¤æ¨¡å¼")
        print("=" * 80)
        
        all_success = True
        repair_summary = {}
        
        for table_name in tables:
            print(f"\nè¡¨å: {table_name}")
            print("-" * 50)
            
            # æ‰§è¡Œè‡ªåŠ¨ä¿®å¤
            repair_success, repair_details = auto_repair_data(
                mysql_connector, mongo_connector, table_name, repair_config
            )
            
            repair_summary[table_name] = repair_details
            
            if not repair_success:
                all_success = False
            
            print(f"\nè¡¨ {table_name} ä¿®å¤ç»“æœ: {'âœ… æˆåŠŸ' if repair_success else 'âŒ å­˜åœ¨å¤±è´¥'}")
            print("-" * 50)
        
        # ç”Ÿæˆä¿®å¤æ±‡æ€»æŠ¥å‘Š
        print("\n" + "=" * 80)
        print("ä¿®å¤æ±‡æ€»æŠ¥å‘Š")
        print("=" * 80)
        
        total_repaired = 0
        total_failed = 0
        
        for table_name, details in repair_summary.items():
            table_repaired = (details.get('missing_repaired', 0) + 
                            details.get('inconsistent_repaired', 0) + 
                            details.get('metadata_repaired', 0))
            table_failed = (details.get('missing_failed', 0) + 
                          details.get('inconsistent_failed', 0) + 
                          details.get('metadata_failed', 0))
            
            total_repaired += table_repaired
            total_failed += table_failed
            
            print(f"\nè¡¨ {table_name}:")
            if details.get('missing_repaired', 0) > 0:
                print(f"  é—æ¼æ•°æ®ä¿®å¤: âœ… {details['missing_repaired']}æ¡")
            if details.get('missing_failed', 0) > 0:
                print(f"  é—æ¼æ•°æ®ä¿®å¤: âŒ {details['missing_failed']}æ¡å¤±è´¥")
            if details.get('inconsistent_repaired', 0) > 0:
                print(f"  ä¸ä¸€è‡´æ•°æ®ä¿®å¤: âœ… {details['inconsistent_repaired']}æ¡")
            if details.get('inconsistent_failed', 0) > 0:
                print(f"  ä¸ä¸€è‡´æ•°æ®ä¿®å¤: âŒ {details['inconsistent_failed']}æ¡å¤±è´¥")
            if details.get('metadata_repaired', 0) > 0:
                print(f"  è¿ç§»å…ƒæ•°æ®ä¿®å¤: âœ… {details['metadata_repaired']}æ¡")
            if details.get('metadata_failed', 0) > 0:
                print(f"  è¿ç§»å…ƒæ•°æ®ä¿®å¤: âŒ {details['metadata_failed']}æ¡å¤±è´¥")
        
        print(f"\næ€»è®¡ä¿®å¤: âœ… {total_repaired}æ¡æˆåŠŸ, âŒ {total_failed}æ¡å¤±è´¥")
        
        if all_success:
            print("\nğŸ‰ æ‰€æœ‰è¡¨çš„æ•°æ®ä¿®å¤å®Œæˆï¼")
        else:
            print("\nâš ï¸  éƒ¨åˆ†è¡¨çš„æ•°æ®ä¿®å¤å­˜åœ¨å¤±è´¥")
        
        return all_success
        
    finally:
        # æ–­å¼€æ•°æ®åº“è¿æ¥
        mysql_connector.disconnect()
        mongo_connector.disconnect()


if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®è¿ç§»å®Œæ•´æ€§éªŒè¯å·¥å…·')
    parser.add_argument('config_file', nargs='?', default='config.json', 
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.json)')
    parser.add_argument('--auto-repair', action='store_true', 
                       help='è‡ªåŠ¨ä¿®å¤å‘ç°çš„é—®é¢˜')
    parser.add_argument('--repair-only', action='store_true',
                       help='ä»…æ‰§è¡Œä¿®å¤ï¼Œä¸è¿›è¡ŒéªŒè¯')
    
    args = parser.parse_args()
    
    print("å¼€å§‹æ•°æ®è¿ç§»å®Œæ•´æ€§éªŒè¯...")
    if args.auto_repair:
        print("ï¼ˆè‡ªåŠ¨ä¿®å¤æ¨¡å¼å·²å¯ç”¨ï¼‰")
    if args.repair_only:
        print("ï¼ˆä»…æ‰§è¡Œä¿®å¤æ¨¡å¼ï¼‰")
    print()
    
    # æ£€æŸ¥è¿ç§»è¿›åº¦
    check_progress()
    print()
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    if args.repair_only:
        # ä»…æ‰§è¡Œä¿®å¤æ¨¡å¼
        success = repair_only_mode(args.config_file)
    else:
        # æ­£å¸¸éªŒè¯æ¨¡å¼ï¼ˆå¯é€‰è‡ªåŠ¨ä¿®å¤ï¼‰
        success = verify_migration(args.config_file, args.auto_repair)
    
    sys.exit(0 if success else 1)